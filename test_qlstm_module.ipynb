{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#import module_utils\n",
    "import module_utils.ansatz as astz\n",
    "import module_utils.feature_map as fm\n",
    "import module_utils.backends as be\n",
    "import module_utils.noise_models as nm\n",
    "\n",
    "from qiskit.primitives import BackendEstimator as Estimator\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLongShortTermMemory(nn.Module):\n",
    "    def __init__(self, feature_map=\"fm_1\", ansatz=\"ghz\", ansatz_reps=2, backend=\"aer_sv\", noise_model=False, input_size=4, hidden_size: int=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_sz = hidden_size\n",
    "\n",
    "        # load predefined quantum hyperparameters\n",
    "        self.backend =be.get_backend(backend)\n",
    "        self.noise_model = nm.get_noise_model(noise_model)\n",
    "        self.feature_map = fm.get_feature_map(feature_map, input_size)\n",
    "        self.ansatz = astz.get_ansatz(ansatz, input_size)\n",
    "        self.ansatz_reps = ansatz_reps\n",
    "\n",
    "        # check feature map and ansatz compatibility\n",
    "        if self.feature_map.num_qubits != self.ansatz.num_qubits:\n",
    "            raise ValueError(f\"Mismatch in number of qubits: feature_map has {self.feature_map.num_qubits}, ansatz has {self.ansatz.num_qubits}.\")\n",
    "\n",
    "        # construct quantum layer\n",
    "        self.VQC = nn.ModuleDict()\n",
    "        self.construct_VQC_layer(feature_map, ansatz, ansatz_reps)\n",
    "\n",
    "        # classical layer\n",
    "        self.input_layer = nn.Linear(input_size + hidden_size, input_size)\n",
    "        self.input_layer_2 = nn.Linear(1, input_size)\n",
    "\n",
    "\n",
    "    def construct_VQC_layer(self, feature_map, ansatz, ansatz_reps):        \n",
    "        # construct the VQC\n",
    "        vqc = self.feature_map.compose(self.ansatz, inplace=False)\n",
    "        # TODO: add ansatz repetitions\n",
    "\n",
    "        # construct the QNN layer\n",
    "        for layer_name in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "            # initialize the QNN layer\n",
    "            obsv = SparsePauliOp([\"Z\"*self.feature_map.num_qubits]) \n",
    "            estimator = Estimator(backend=self.backend, options={'NoiseModel': self.noise_model})\n",
    "            qnn = EstimatorQNN(\n",
    "                    circuit=vqc,\n",
    "                    estimator=estimator,\n",
    "                    observables=obsv,\n",
    "                    input_params=self.feature_map.parameters,\n",
    "                    weight_params=self.ansatz.parameters,\n",
    "                    input_gradients=True\n",
    "            )\n",
    "            self.VQC[layer_name] = TorchConnector(qnn)\n",
    "\n",
    "\n",
    "    def forward(self, X: torch.Tensor, memory_states: tuple = None):\n",
    "        if memory_states is None:\n",
    "            # initialize memory states\n",
    "            h_t, c_t = (torch.zeros(1, self.hidden_sz).to(X.device), \n",
    "                        torch.zeros(1, self.hidden_sz).to(X.device))\n",
    "        else:\n",
    "            h_t, c_t = memory_states \n",
    "\n",
    "        outputs = []\n",
    "        for sample_x in X: \n",
    "            v_t = torch.cat([sample_x, h_t], dim=0)\n",
    "            v_t_input = self.input_layer(v_t.reshape(1, -1)).reshape(-1)\n",
    "            # QNN layer\n",
    "            f_t = torch.sigmoid(self.VQC[\"1\"](v_t_input))\n",
    "            i_t = torch.sigmoid(self.VQC[\"2\"](v_t_input))\n",
    "            c_tilde = torch.tanh(self.VQC[\"3\"](v_t_input))\n",
    "            c_t = f_t * c_t + i_t * c_tilde\n",
    "            o_t = torch.sigmoid(self.VQC[\"4\"](v_t_input))\n",
    "            h_t = self.VQC[\"5\"]((self.input_layer_2(o_t * torch.tanh(c_t))))\n",
    "            outputs.append(h_t.unsqueeze(0))\n",
    "        \n",
    "        outputs = torch.cat(outputs, dim=0)\n",
    "        # reshape from shape (sequence, batch, feature) to (batch, sequence, feature)\n",
    "        outputs = outputs.transpose(0, 1).contiguous()\n",
    "\n",
    "        return outputs, (h_t, c_t)\n",
    "    \n",
    "    def get_desription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qLSTM = QuantumLongShortTermMemory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
